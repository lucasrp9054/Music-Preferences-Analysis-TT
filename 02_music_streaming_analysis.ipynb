{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E0vqbgi9ay0H"
   },
   "source": [
    "# Music Streaming Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fhq_eyov_Zcs"
   },
   "source": [
    "# Content <a id='back'></a>\n",
    "\n",
    "* [Introduction](#intro)\n",
    "* [Step 1. Data Overview](#data_review)\n",
    "    * [Conclusions](#data_review_conclusions)\n",
    "* [Step 2. Data Preprocessing](#data_preprocessing)\n",
    "    * [2.1 Header Style](#header_style)\n",
    "    * [2.2 Missing Values](#missing_values)\n",
    "    * [2.3 Duplicates](#duplicates)\n",
    "    * [2.4 Conclusions](#data_preprocessing_conclusions)\n",
    "* [Step 3. Hypothesis Testing](#hypothesis)\n",
    "    * [3.1 Hypothesis 1: User Activity in Both Cities](#activity)\n",
    "* [Conclusions](#end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUC88oWjTJw2"
   },
   "source": [
    "## Introduction <a id='intro'></a>\n",
    "An analyst's job is to analyze data to gain valuable insights and make informed decisions based on them. This process consists of several steps, such as data overview, data preprocessing, and hypothesis testing.\n",
    "\n",
    "Whenever we conduct research, we need to formulate a hypothesis that we can later test. Sometimes we accept these hypotheses; other times, we reject them. To make the right choices, a business must be able to understand if it is making the right assumptions or not.\n",
    "\n",
    "In this project, you will compare the music preferences of the inhabitants of Springfield and Shelbyville. You will study data from an online music streaming service to test the hypothesis presented below and compare the behavior of users in these two cities.\n",
    "\n",
    "### Objective:\n",
    "Test the hypothesis:\n",
    "\n",
    "1. User activity differs depending on the day of the week and the city.\n",
    "\n",
    "\n",
    "### Steps\n",
    "Data on user behavior is stored in the file `/datasets/music_project_en.csv`. There is no information about the quality of the data, so it will be necessary to examine it before testing the hypothesis.\n",
    "\n",
    "First, you will evaluate the quality of the data and see if its problems are significant. Then, during data preprocessing, you will try to address the most critical issues.\n",
    "\n",
    "Your project will consist of three steps:\n",
    "1. Data overview\n",
    "2. Data preprocessing\n",
    "3. Hypothesis testing\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hDt6pg-Rw-1U"
   },
   "source": [
    "[Return to index](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ml1hmfXC_Zcs"
   },
   "source": [
    "## Step 1. Data Overview <a id='data_review'></a>\n",
    "\n",
    "Open the data and examine it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AXN7PHPN_Zcs"
   },
   "outputs": [],
   "source": [
    "# importing pandas\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SG23P8tt_Zcs"
   },
   "source": [
    "Read the file `music_project_en.csv` from the folder `/datasets/` and save it on the variable `df`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fFVu7vqh_Zct"
   },
   "outputs": [],
   "source": [
    "# reading the file and storing it in df\n",
    "df = pd.read_csv('/datasets/music_project_en.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oWTVX3gW_Zct"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>Track</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>City</th>\n",
       "      <th>time</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FFB692EC</td>\n",
       "      <td>Kamigata To Boots</td>\n",
       "      <td>The Mass Missile</td>\n",
       "      <td>rock</td>\n",
       "      <td>Shelbyville</td>\n",
       "      <td>20:28:33</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55204538</td>\n",
       "      <td>Delayed Because of Accident</td>\n",
       "      <td>Andreas Rönnberg</td>\n",
       "      <td>rock</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>14:07:09</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20EC38</td>\n",
       "      <td>Funiculì funiculà</td>\n",
       "      <td>Mario Lanza</td>\n",
       "      <td>pop</td>\n",
       "      <td>Shelbyville</td>\n",
       "      <td>20:58:07</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A3DD03C9</td>\n",
       "      <td>Dragons in the Sunset</td>\n",
       "      <td>Fire + Ice</td>\n",
       "      <td>folk</td>\n",
       "      <td>Shelbyville</td>\n",
       "      <td>08:37:09</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E2DC1FAE</td>\n",
       "      <td>Soul People</td>\n",
       "      <td>Space Echo</td>\n",
       "      <td>dance</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>08:34:34</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>842029A1</td>\n",
       "      <td>Chains</td>\n",
       "      <td>Obladaet</td>\n",
       "      <td>rusrap</td>\n",
       "      <td>Shelbyville</td>\n",
       "      <td>13:09:41</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4CB90AA5</td>\n",
       "      <td>True</td>\n",
       "      <td>Roman Messer</td>\n",
       "      <td>dance</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>13:00:07</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>F03E1C1F</td>\n",
       "      <td>Feeling This Way</td>\n",
       "      <td>Polina Griffith</td>\n",
       "      <td>dance</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>20:47:49</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8FA1D3BE</td>\n",
       "      <td>L’estate</td>\n",
       "      <td>Julia Dalia</td>\n",
       "      <td>ruspop</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>09:17:40</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>E772D5C0</td>\n",
       "      <td>Pessimist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dance</td>\n",
       "      <td>Shelbyville</td>\n",
       "      <td>21:20:49</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     userID                        Track            artist   genre  \\\n",
       "0  FFB692EC            Kamigata To Boots  The Mass Missile    rock   \n",
       "1  55204538  Delayed Because of Accident  Andreas Rönnberg    rock   \n",
       "2    20EC38            Funiculì funiculà       Mario Lanza     pop   \n",
       "3  A3DD03C9        Dragons in the Sunset        Fire + Ice    folk   \n",
       "4  E2DC1FAE                  Soul People        Space Echo   dance   \n",
       "5  842029A1                       Chains          Obladaet  rusrap   \n",
       "6  4CB90AA5                         True      Roman Messer   dance   \n",
       "7  F03E1C1F             Feeling This Way   Polina Griffith   dance   \n",
       "8  8FA1D3BE                     L’estate       Julia Dalia  ruspop   \n",
       "9  E772D5C0                    Pessimist               NaN   dance   \n",
       "\n",
       "        City        time        Day  \n",
       "0  Shelbyville  20:28:33  Wednesday  \n",
       "1  Springfield  14:07:09     Friday  \n",
       "2  Shelbyville  20:58:07  Wednesday  \n",
       "3  Shelbyville  08:37:09     Monday  \n",
       "4  Springfield  08:34:34     Monday  \n",
       "5  Shelbyville  13:09:41     Friday  \n",
       "6  Springfield  13:00:07  Wednesday  \n",
       "7  Springfield  20:47:49  Wednesday  \n",
       "8  Springfield  09:17:40     Friday  \n",
       "9  Shelbyville  21:20:49  Wednesday  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the first 10 rows of the df table\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DSf2kIb-_Zct"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 65079 entries, 0 to 65078\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0     userID  65079 non-null  object\n",
      " 1   Track     63736 non-null  object\n",
      " 2   artist    57512 non-null  object\n",
      " 3   genre     63881 non-null  object\n",
      " 4     City    65079 non-null  object\n",
      " 5   time      65079 non-null  object\n",
      " 6   Day       65079 non-null  object\n",
      "dtypes: object(7)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# getting general information about our data\n",
    "\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3826"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many duplicate rows are there in the DataFrame\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  userID       0\n",
       "Track       1343\n",
       "artist      7567\n",
       "genre       1198\n",
       "  City         0\n",
       "time           0\n",
       "Day            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of null values in each column\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TaQ2Iwbr_Zct"
   },
   "source": [
    "Here are our observations about the table. It contains seven columns. They store the same data type: object.\n",
    "\n",
    "According to the documentation:\n",
    "\n",
    "- 'userID' — user identification\n",
    "- 'Track' — song title\n",
    "- 'artist' — artist's name\n",
    "- 'genre' — music genre\n",
    "- 'City' — user's city\n",
    "- 'time' — the exact time the song was played\n",
    "- 'Day' — day of the week\n",
    "\n",
    "We can see three style issues in the table headers:\n",
    "\n",
    "1. Some headers are written in uppercase, others are in lowercase.\n",
    "2. Some headers contain spaces.\n",
    "3. The 'userID' field has a leading space that could lead to errors later, in addition to having mixed case letters. The other fields have similar issues, where some have mixed case and others are entirely lowercase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MCB6-dXG_Zct"
   },
   "source": [
    "### Write your observations. Here are some questions that can help: <a id='data_review_conclusions'></a>\n",
    "\n",
    "`1. What kind of data do we have in the rows? And how can we understand the columns?`\n",
    "All columns have categorical data (object type). Each field can be interpreted as:\n",
    "\n",
    "'userID' — user identification\n",
    "'Track' — song title\n",
    "'artist' — artist's name\n",
    "'genre' — music genre\n",
    "'City' — user's city\n",
    "'time' — the time of day the song was played\n",
    "'Day' — day of the week\n",
    "\n",
    "`2. Is this data sufficient to answer our hypothesis, or do we need more data?`\n",
    "I believe it is possible to answer the proposed hypothesis, but the answer will be quite superficial and with little basis.\n",
    "\n",
    "One of the main problems I identify is in the 'Day' field, which only informs the name of the day of the week (like \"Wednesday\"), without providing the full date of playback. This considerably limits the analysis, as valuable information could be obtained from the exact date, such as the season, holidays, and seasonal events—all with the potential to directly influence users' musical behavior.\n",
    "\n",
    "For example, it is reasonable to assume that on commemorative dates such as June Festivals, Carnival, Christmas, and other regional or national occasions, the most listened to musical styles tend to change. Ignoring this factor can lead to inaccurate or biased interpretations of activity patterns.\n",
    "\n",
    "Furthermore, the DataFrame has a field that records the exact time the music was played (time). This data should also be considered, as user behavior can vary greatly throughout the day—listening to music at 9 am is not the same as at 11 pm.\n",
    "\n",
    "`3. Did you notice any problems in the data, such as missing values, duplicates, or wrong data types?`\n",
    "\n",
    "Yes.\n",
    "\n",
    "I could see that using the `df.isna().sum()` method revealed the existence of null values in the 'Track', 'artist', and 'genre' columns.\n",
    "\n",
    "As for duplicate rows, using `df.duplicated().sum()`: 3826.\n",
    "\n",
    "However, regarding the data types, I believe they are in order, with the exception of the data in the `time` column, which, although I am not very familiar with it, being a string is probably not the most indicated, as there should be a better type when I think about how to use its values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3eL__vcwViOi"
   },
   "source": [
    "[Return to index](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SjYF6Ub9_Zct"
   },
   "source": [
    "## Step 2. Data Preprocessing <a id='data_preprocessing'></a>\n",
    "\n",
    "The goal here is to prepare the data for analysis.\n",
    "The first step is to resolve all issues with the header. Then we can move on to missing values and duplicates. Let's begin.\n",
    "\n",
    "Correct the formatting in the table headers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dIaKXr29_Zct"
   },
   "source": [
    "### Header Style <a id='header_style'></a>\n",
    "Print the table headers (the column names):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oKOTdF_Q_Zct"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['  userID', 'Track', 'artist', 'genre', '  City  ', 'time', 'Day'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# print the column names\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zj5534cv_Zct"
   },
   "source": [
    "Change the table headers according to good style practices:\n",
    "\n",
    "- All characters must be lowercase\n",
    "- Delete spaces\n",
    "- If the name has multiple words, use snake_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6I_RwwMhzM4e"
   },
   "outputs": [],
   "source": [
    "# Looping through the headers and converting everything to lowercase\n",
    "new_names = []\n",
    "\n",
    "for col in df.columns:\n",
    "    new_names.append(col.lower())\n",
    "\n",
    "df.columns = new_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vVQXbFyJzSYl"
   },
   "outputs": [],
   "source": [
    "# Looping through the headers and removing spaces\n",
    "new_names = []\n",
    "\n",
    "for col in df.columns:\n",
    "    new_names.append(col.strip())\n",
    "\n",
    "df.columns = new_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to apply the underscore-instead-of-space rule to the `userid` column. It should be `user_id`. Rename this column and print the names of all columns when you're done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ISlFqs5y_Zct"
   },
   "outputs": [],
   "source": [
    "# Renaming the \"userid\" column\n",
    "new_name = {'userid': 'user_id'}\n",
    "df.rename(columns=new_name, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1dqbh00J_Zct"
   },
   "source": [
    "Check the result. Print the headers again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d4NOAmTW_Zct"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['user_id', 'track', 'artist', 'genre', 'city', 'time', 'day'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# checking the result: the list of headers\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYJk6ksJVpOl"
   },
   "source": [
    "[Return to index](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ISfbcfY_Zct"
   },
   "source": [
    "### Missing Values <a id='missing_values'></a>\n",
    "\n",
    "First, find the number of missing values in the table. You need to use two methods in sequence to get the number of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RskX29qr_Zct"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id       0\n",
       "track      1343\n",
       "artist     7567\n",
       "genre      1198\n",
       "city          0\n",
       "time          0\n",
       "day           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating the number of missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qubhgnlO_Zct"
   },
   "source": [
    "Not all missing values affect the research. For example, the missing values in `track` and `artist` are not critical. You can simply replace them with default values, like the string `unknown`.\n",
    "\n",
    "But missing values in `genre` can affect the comparison of music preferences in Springfield and Shelbyville. In real life, it would be useful to find out the reasons why the data is missing and try to fix it. But we don't have that possibility in this project. So, you will have to:\n",
    "\n",
    "- Fill in these missing values with a default value\n",
    "- Evaluate how much the missing values might affect your analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fSv2laPA_Zct"
   },
   "source": [
    "Replace the missing values in the `track`, `artist`, and `genre` columns with the string `unknown`. As we showed in the lessons, the best way to do this is to create a list to store the names of the columns in which we need to make the substitution. Then, use this list and loop through the columns where the substitution is needed and make the substitution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KplB5qWs_Zct"
   },
   "outputs": [],
   "source": [
    "# looping through the headers and replacing missing values with 'unknown'\n",
    "columns = ['track', 'artist', 'genre']\n",
    "df[columns] = df[columns].fillna('unknown')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ilsm-MZo_Zct"
   },
   "source": [
    "Now check the result to make sure the dataset does not contain missing values after the substitution. To do this, count the missing values again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tq4nYRX4_Zct"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id    0\n",
       "track      0\n",
       "artist     0\n",
       "genre      0\n",
       "city       0\n",
       "time       0\n",
       "day        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counting the missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74ZIBmq9VrsK"
   },
   "source": [
    "[Return to index](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BWKRtBJ3_Zct"
   },
   "source": [
    "### Duplicates <a id='duplicates'></a>\n",
    "Find the number of explicit duplicates in the table. Remember that you need to apply two methods in sequence to get the number of explicit duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "36eES_S0_Zct"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3826"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counting explicit duplicates\n",
    "df.duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ot25h6XR_Zct"
   },
   "source": [
    "Now discard all duplicates. To do this, call the method that does exactly that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "exFHq6tt_Zct"
   },
   "outputs": [],
   "source": [
    "# removing explicit duplicates\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Im2YwBEG_Zct"
   },
   "source": [
    "Now let's check if we have discarded all duplicates. Count explicit duplicates once more to make sure you have removed all of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-8PuNWQ0_Zct"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# checking for duplicates again\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QlFBsxAr_Zct"
   },
   "source": [
    "Now we want to get rid of implicit duplicates in the `genre` column. For example, the name of a genre can be written in different ways. Some errors will also affect the result.\n",
    "\n",
    "To do this, let's start by printing a list of unique genre names, sorted in alphabetical order. To do this:\n",
    "\n",
    "- Extract the genre column from the DataFrame\n",
    "- Call the method that will return all unique values in the extracted column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JIUcqzZN_Zct"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['rock', 'pop', 'folk', 'dance', 'rusrap', 'ruspop', 'world',\n",
       "       'electronic', 'unknown', 'alternative', 'children', 'rnb', 'hip',\n",
       "       'jazz', 'postrock', 'latin', 'classical', 'metal', 'reggae',\n",
       "       'triphop', 'blues', 'instrumental', 'rusrock', 'dnb', 'türk',\n",
       "       'post', 'country', 'psychedelic', 'conjazz', 'indie',\n",
       "       'posthardcore', 'local', 'avantgarde', 'punk', 'videogame',\n",
       "       'techno', 'house', 'christmas', 'melodic', 'caucasian',\n",
       "       'reggaeton', 'soundtrack', 'singer', 'ska', 'salsa', 'ambient',\n",
       "       'film', 'western', 'rap', 'beats', \"hard'n'heavy\", 'progmetal',\n",
       "       'minimal', 'tropical', 'contemporary', 'new', 'soul', 'holiday',\n",
       "       'german', 'jpop', 'spiritual', 'urban', 'gospel', 'nujazz',\n",
       "       'folkmetal', 'trance', 'miscellaneous', 'anime', 'hardcore',\n",
       "       'progressive', 'korean', 'numetal', 'vocal', 'estrada', 'tango',\n",
       "       'loungeelectronic', 'classicmetal', 'dubstep', 'club', 'deep',\n",
       "       'southern', 'black', 'folkrock', 'fitness', 'french', 'disco',\n",
       "       'religious', 'hiphop', 'drum', 'extrememetal', 'türkçe',\n",
       "       'experimental', 'easy', 'metalcore', 'modern', 'argentinetango',\n",
       "       'old', 'swing', 'breaks', 'eurofolk', 'stonerrock', 'industrial',\n",
       "       'funk', 'middle', 'variété', 'other', 'adult', 'christian',\n",
       "       'thrash', 'gothic', 'international', 'muslim', 'relax', 'schlager',\n",
       "       'caribbean', 'nu', 'breakbeat', 'comedy', 'chill', 'newage',\n",
       "       'specialty', 'uzbek', 'k-pop', 'balkan', 'chinese', 'meditative',\n",
       "       'dub', 'power', 'death', 'grime', 'arabesk', 'romance', 'flamenco',\n",
       "       'leftfield', 'european', 'tech', 'newwave', 'dancehall', 'mpb',\n",
       "       'piano', 'top', 'bigroom', 'opera', 'celtic', 'tradjazz',\n",
       "       'acoustic', 'epicmetal', 'hip-hop', 'historisch', 'downbeat',\n",
       "       'downtempo', 'africa', 'audiobook', 'jewish', 'sängerportrait',\n",
       "       'deutschrock', 'eastern', 'action', 'future', 'electropop',\n",
       "       'folklore', 'bollywood', 'marschmusik', 'rnr', 'karaoke', 'indian',\n",
       "       'rancheras', 'afrikaans', 'rhythm', 'sound', 'deutschspr', 'trip',\n",
       "       'lovers', 'choral', 'dancepop', 'retro', 'smooth', 'mexican',\n",
       "       'brazilian', 'ïîï', 'mood', 'surf', 'gangsta', 'inspirational',\n",
       "       'idm', 'ethnic', 'bluegrass', 'broadway', 'animated', 'americana',\n",
       "       'karadeniz', 'rockabilly', 'colombian', 'self', 'hop', 'sertanejo',\n",
       "       'japanese', 'canzone', 'lounge', 'sport', 'ragga', 'traditional',\n",
       "       'gitarre', 'frankreich', 'emo', 'laiko', 'cantopop', 'glitch',\n",
       "       'documentary', 'oceania', 'popeurodance', 'dark', 'vi', 'grunge',\n",
       "       'hardstyle', 'samba', 'garage', 'art', 'folktronica', 'entehno',\n",
       "       'mediterranean', 'chamber', 'cuban', 'taraftar', 'gypsy',\n",
       "       'hardtechno', 'shoegazing', 'bossa', 'latino', 'worldbeat',\n",
       "       'malaysian', 'baile', 'ghazal', 'arabic', 'popelectronic', 'acid',\n",
       "       'kayokyoku', 'neoklassik', 'tribal', 'tanzorchester', 'native',\n",
       "       'independent', 'cantautori', 'handsup', 'punjabi', 'synthpop',\n",
       "       'rave', 'französisch', 'quebecois', 'speech', 'soulful', 'jam',\n",
       "       'ram', 'horror', 'orchestral', 'neue', 'roots', 'slow', 'jungle',\n",
       "       'indipop', 'axé', 'fado', 'showtunes', 'arena', 'irish',\n",
       "       'mandopop', 'forró', 'dirty', 'regional'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewing unique genre names\n",
    "df['genre'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qej-Qmuo_Zct"
   },
   "source": [
    "Look at the list and find implicit duplicates of the `hiphop` genre. These could be misspelled names, or alternative names for the same genre.\n",
    "\n",
    "You will see the following implicit duplicates:\n",
    "\n",
    "* `hip`\n",
    "* `hop`\n",
    "* `hip-hop`\n",
    "\n",
    "To get rid of them, create a function `replace_wrong_genres()` with two parameters:\n",
    "\n",
    "* `wrong_genres`= — this is a list containing all the values you need to replace\n",
    "\n",
    "* `correct_genre`= — this is a string you will use for the substitution\n",
    "\n",
    "As a result, the function should correct the names in the `genre` column of the `df` table, that is, replacing each value from the `wrong_genres` list with values from `correct_genre`.\n",
    "\n",
    "Within the function body, use a `for` loop to iterate through the list of wrong genres, extract the `genre` column, and apply the `replace` method to make the corrections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ErNDkmns_Zct"
   },
   "outputs": [],
   "source": [
    "# function to replace implicit duplicates\n",
    "def replace_wrong_genres(data, column, wrong_names, correct_name):\n",
    "    data[column].replace(wrong_names, correct_name, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDoBJxbA_Zct"
   },
   "source": [
    "Now, call the `replace_wrong_genres()` function and pass appropriate arguments so that it cleans up implicit duplicates (`hip`, `hop`, and `hip-hop`) by replacing them with `hiphop`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YN5i2hpmSo09"
   },
   "outputs": [],
   "source": [
    "# removing implicit duplicates\n",
    "wrong_names = ['hip', 'hop', 'hip-hop']\n",
    "correct_name = 'hiphop'\n",
    "df = replace_wrong_genres(df, 'genre', wrong_names, correct_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQKF16_RG15m"
   },
   "source": [
    "Make sure the duplicate names have been removed. Print the list of unique values from the `genre` column once more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wvixALnFG15m"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['rock', 'pop', 'folk', 'dance', 'rusrap', 'ruspop', 'world',\n",
       "       'electronic', 'unknown', 'alternative', 'children', 'rnb',\n",
       "       'hiphop', 'jazz', 'postrock', 'latin', 'classical', 'metal',\n",
       "       'reggae', 'triphop', 'blues', 'instrumental', 'rusrock', 'dnb',\n",
       "       'türk', 'post', 'country', 'psychedelic', 'conjazz', 'indie',\n",
       "       'posthardcore', 'local', 'avantgarde', 'punk', 'videogame',\n",
       "       'techno', 'house', 'christmas', 'melodic', 'caucasian',\n",
       "       'reggaeton', 'soundtrack', 'singer', 'ska', 'salsa', 'ambient',\n",
       "       'film', 'western', 'rap', 'beats', \"hard'n'heavy\", 'progmetal',\n",
       "       'minimal', 'tropical', 'contemporary', 'new', 'soul', 'holiday',\n",
       "       'german', 'jpop', 'spiritual', 'urban', 'gospel', 'nujazz',\n",
       "       'folkmetal', 'trance', 'miscellaneous', 'anime', 'hardcore',\n",
       "       'progressive', 'korean', 'numetal', 'vocal', 'estrada', 'tango',\n",
       "       'loungeelectronic', 'classicmetal', 'dubstep', 'club', 'deep',\n",
       "       'southern', 'black', 'folkrock', 'fitness', 'french', 'disco',\n",
       "       'religious', 'drum', 'extrememetal', 'türkçe', 'experimental',\n",
       "       'easy', 'metalcore', 'modern', 'argentinetango', 'old', 'swing',\n",
       "       'breaks', 'eurofolk', 'stonerrock', 'industrial', 'funk', 'middle',\n",
       "       'variété', 'other', 'adult', 'christian', 'thrash', 'gothic',\n",
       "       'international', 'muslim', 'relax', 'schlager', 'caribbean', 'nu',\n",
       "       'breakbeat', 'comedy', 'chill', 'newage', 'specialty', 'uzbek',\n",
       "       'k-pop', 'balkan', 'chinese', 'meditative', 'dub', 'power',\n",
       "       'death', 'grime', 'arabesk', 'romance', 'flamenco', 'leftfield',\n",
       "       'european', 'tech', 'newwave', 'dancehall', 'mpb', 'piano', 'top',\n",
       "       'bigroom', 'opera', 'celtic', 'tradjazz', 'acoustic', 'epicmetal',\n",
       "       'historisch', 'downbeat', 'downtempo', 'africa', 'audiobook',\n",
       "       'jewish', 'sängerportrait', 'deutschrock', 'eastern', 'action',\n",
       "       'future', 'electropop', 'folklore', 'bollywood', 'marschmusik',\n",
       "       'rnr', 'karaoke', 'indian', 'rancheras', 'afrikaans', 'rhythm',\n",
       "       'sound', 'deutschspr', 'trip', 'lovers', 'choral', 'dancepop',\n",
       "       'retro', 'smooth', 'mexican', 'brazilian', 'ïîï', 'mood', 'surf',\n",
       "       'gangsta', 'inspirational', 'idm', 'ethnic', 'bluegrass',\n",
       "       'broadway', 'animated', 'americana', 'karadeniz', 'rockabilly',\n",
       "       'colombian', 'self', 'sertanejo', 'japanese', 'canzone', 'lounge',\n",
       "       'sport', 'ragga', 'traditional', 'gitarre', 'frankreich', 'emo',\n",
       "       'laiko', 'cantopop', 'glitch', 'documentary', 'oceania',\n",
       "       'popeurodance', 'dark', 'vi', 'grunge', 'hardstyle', 'samba',\n",
       "       'garage', 'art', 'folktronica', 'entehno', 'mediterranean',\n",
       "       'chamber', 'cuban', 'taraftar', 'gypsy', 'hardtechno',\n",
       "       'shoegazing', 'bossa', 'latino', 'worldbeat', 'malaysian', 'baile',\n",
       "       'ghazal', 'arabic', 'popelectronic', 'acid', 'kayokyoku',\n",
       "       'neoklassik', 'tribal', 'tanzorchester', 'native', 'independent',\n",
       "       'cantautori', 'handsup', 'punjabi', 'synthpop', 'rave',\n",
       "       'französisch', 'quebecois', 'speech', 'soulful', 'jam', 'ram',\n",
       "       'horror', 'orchestral', 'neue', 'roots', 'slow', 'jungle',\n",
       "       'indipop', 'axé', 'fado', 'showtunes', 'arena', 'irish',\n",
       "       'mandopop', 'forró', 'dirty', 'regional'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for duplicate values\n",
    "df['genre'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ALgNbvF3VtPA"
   },
   "source": [
    "[Return to index](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jz6a9-7HQUDd"
   },
   "source": [
    "### Your observations <a id='data_preprocessing_conclusions'></a>\n",
    "\n",
    "`Briefly describe what you noticed when analyzing duplicates, as well as the approach you used to eliminate them and the results you achieved.`\n",
    "\n",
    "When analyzing the data, I realized that in columns with many unique values or similar names, it is common to have implicit duplicates—such as spelling or capitalization variations (`hip-hop`, `HipHop`, `hip`) or even incorrect entries. These records often go unnoticed in a superficial analysis. I believe there are also cases where the analyst is unaware of the correct spelling, and these inconsistencies go unnoticed by those who do not have expertise in the subject.\n",
    "\n",
    "To eliminate these inconsistencies, I used a manual approach, replacing wrong values with a function that maps the incorrect names to the correct value. Although functional, this approach has limitations: it requires prior knowledge of the existing variations, besides being not very scalable and dependent on manual intervention, which is not attractive.\n",
    "\n",
    "The result was that I was able to standardize the incorrect records to a single spelling and format for the `hiphop` music genre within the `genre` column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eK1es74rVujj"
   },
   "source": [
    "[Return to index](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WttZHXH0SqKk"
   },
   "source": [
    "## Step 3. Hypothesis Testing\n",
    " <a id='hypothesis'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Im936VVi_Zcu"
   },
   "source": [
    "### Hypothesis: comparison of user behavior in the two cities <a id='activity'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nwt_MuaL_Zcu"
   },
   "source": [
    "The hypothesis states that there are differences in music consumption by users in Springfield and Shelbyville. To test the hypothesis, use the data from the three weekdays: Monday, Wednesday, and Friday.\n",
    "\n",
    "* Group the users by city.\n",
    "* Compare the number of songs played by each group on Monday, Wednesday, and Friday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_springfield = df[df['city'] == 'Springfield'] # Springfield Users\n",
    "df_shelbyville = df[df['city'] == 'Shelbyville'] # Shelbyville Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0_Qs96oh_Zcu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qtd de músicas tocadas em Springfield:  42741\n",
      "Qtd de músicas tocadas em Shelbyville:  18512\n"
     ]
    }
   ],
   "source": [
    "# Counting the songs played in each city\n",
    "print('Number of songs played in Springfield: ', df_springfield['track'].count())\n",
    "print('Number of songs played in Shelbyville: ', df_shelbyville['track'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_Qx-3NewAnK"
   },
   "source": [
    "`Comment on your observations here`\n",
    "\n",
    "I grouped the user groups from each city into a new variable each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzli3w8o_Zcu"
   },
   "source": [
    "Now let's group the data by day of the week and find the number of songs played on Monday, Wednesday, and Friday. Use the same approach as before, but now we need to group the data differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uZMKjiJz_Zcu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monday - Springfield: 15740 / Shelbyville: 5614\n",
      "Wednesday - Springfield: 11056 / Shelbyville: 7003\n",
      "Friday - Springfield: 15945 / Shelbyville: 5895\n"
     ]
    }
   ],
   "source": [
    "# Calculating the songs listened to on each of these three days\n",
    "def music_quantity_day(data, collumn_day, collumn_music, days):\n",
    "    music_quntity = [] # list to store the number of songs for each day of the week\n",
    "    for day in days: # 3 days = monday, wednesday, and friday\n",
    "        music_quntity.append(data[data[collumn_day] == day][collumn_music].count())\n",
    "    return music_quntity\n",
    "\n",
    "# list of days to analyze\n",
    "days = ['Monday', 'Wednesday', 'Friday']\n",
    "qtd_springfield = music_quantity_day(df_springfield, 'day', 'track', days)\n",
    "qtd_shelbyville = music_quantity_day(df_shelbyville, 'day', 'track', days)\n",
    "\n",
    "for i, day in enumerate(days):\n",
    "    print(f\"{day} - Springfield: {qtd_springfield[i]} / Shelbyville: {qtd_shelbyville[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cC2tNrlL_Zcu"
   },
   "source": [
    "`Comment on your observations here`\n",
    "\n",
    "Previously, I had made 6 variations of the print statement, but then I thought it would be less cluttered to use a similar function as I did when handling the inconsistent 'hiphop' data in the 'genre' column.\n",
    "\n",
    "I made a function that takes a DataFrame, the day column, the music column, and a list with the days for which I want to get the song counts as parameters. It returns a list with the counts for each day, which I save into 2 variables corresponding to each of the two cities, and then I print these values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "POzs8bGa_Zcu"
   },
   "source": [
    "You have just learned how to count entries by grouping them by city or by day. And now you need to write a function that can count entries simultaneously based on both criteria.\n",
    "\n",
    "Create the `number_tracks()` function to calculate the number of songs played on a given day and in a given city. The function should accept two parameters:\n",
    "\n",
    "* `day`: a day of the week for which we need to filter the data. For example, `Monday`.\n",
    "* `city`: a city for which we need to filter the data. For example, `Springfield`.\n",
    "\n",
    "Inside the function, you will apply consecutive filtering with logical indexing.\n",
    "\n",
    "First, filter the data by day and then filter the resulting table by city.\n",
    "\n",
    "After filtering the data using both criteria, count the number of values in the 'user_id' column of the resulting table. The result of the count will represent the number of entries you want to find. Store the result in a new variable and print it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nz3GdQB1_Zcu"
   },
   "outputs": [],
   "source": [
    "# Declare the number_tracks() function with two parameters: day= and city=.\n",
    "def number_tracks(day, city):\n",
    "    # Filter by day\n",
    "    filtered_by_day = df[df['day'] == day]\n",
    "    # Filter by city\n",
    "    filtered_by_city = filtered_by_day[filtered_by_day['city'] == city]\n",
    "    # Count how many 'user_id' records exist after the two filters\n",
    "    total = filtered_by_city['user_id'].count()\n",
    "    # Return the result\n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ytf7xFrFJQ2r"
   },
   "source": [
    "Call the `number_tracks()` function six times, changing the parameter values, so you can retrieve the data for both cities for each of the three days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rJcRATNQ_Zcu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15740\n"
     ]
    }
   ],
   "source": [
    "# the number of songs played in Springfield on Monday\n",
    "total = number_tracks('Monday', 'Springfield')\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hq_ncZ5T_Zcu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5614\n"
     ]
    }
   ],
   "source": [
    "# the number of songs played in Shelbyville on Monday\n",
    "total = number_tracks('Monday', 'Shelbyville')\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_NTy2VPU_Zcu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11056\n"
     ]
    }
   ],
   "source": [
    "# the number of songs played in Springfield on Wednesday\n",
    "total = number_tracks('Wednesday', 'Springfield')\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j2y3TAwo_Zcu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7003\n"
     ]
    }
   ],
   "source": [
    "# the number of songs played in Shelbyville on Wednesday\n",
    "total = number_tracks('Wednesday', 'Shelbyville')\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vYDw5u_K_Zcu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15945\n"
     ]
    }
   ],
   "source": [
    "# the number of songs played in Springfield on Friday\n",
    "total = number_tracks('Friday', 'Springfield')\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8_yzFtW3_Zcu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5895\n"
     ]
    }
   ],
   "source": [
    "# the number of songs played in Shelbyville on Friday\n",
    "total = number_tracks('Friday', 'Shelbyville')\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-EgPIHYu_Zcu"
   },
   "source": [
    "**Conclusions**\n",
    "\n",
    "Comment on whether the third hypothesis is correct or should be rejected. Explain your reasoning.`\n",
    "\n",
    "As I said before, it is very difficult to get a good result with the current data; there is data that could be added that would likely provide a more accurate answer. Therefore, I believe the hypothesis in its current state should be rejected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p7nFQajCVw5B"
   },
   "source": [
    "[Return to index](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykKQ0N65_Zcv"
   },
   "source": [
    "# Conclusions <a id='end'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjUwbHb3_Zcv"
   },
   "source": [
    "Summarize your conclusions about the hypothesis here`\n",
    "\n",
    "Although the data shows numerical differences in the number of tracks played between Springfield and Shelbyville on certain days of the week, accepting the hypothesis based solely on this would be premature. The DataFrame treats all Mondays, Wednesdays, and Fridays as equivalent, without considering variations between weeks, months, or seasonal events that could influence user behavior. Furthermore, there is no normalization for population size or the number of active users in each city, which makes the comparison arbitrary. That is, the fact that one city has more plays on a given day does not necessarily indicate a distinct behavior pattern—it could simply reflect a larger user base. Therefore, the hypothesis should be rejected or, at the very least, considered inconclusive with the current data.\n",
    "\n",
    "Simply put, I must reject this hypothesis, as the results provided with the current DataFrame are weak."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ju4AHDSgV1FE"
   },
   "source": [
    "[Return to index](#back)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "E0vqbgi9ay0H",
    "VUC88oWjTJw2"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
